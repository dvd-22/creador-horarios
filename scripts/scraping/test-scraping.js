import scrapeMaterias from "./scrape-materias.js";
import scrapeSchedules from "./scrape-schedules.js";
import convertToJson from "./convert-to-json.js";

async function runFullScraping() {
	console.log("üöÄ Starting full scraping process...");

	try {
		// Step 1: Scrape materias
		console.log("\nüìö Step 1: Scraping materias...");
		await scrapeMaterias();

		// Step 2: Scrape schedules
		console.log("\nüìÖ Step 2: Scraping schedules...");
		await scrapeSchedules();

		// Step 3: Convert to JSON
		console.log("\nüîÑ Step 3: Converting to JSON...");
		await convertToJson();

		console.log("\nüéâ Full scraping process completed successfully!");
		console.log("üìÅ Generated files:");
		console.log("  - materias.csv");
		console.log("  - materias.json");
		console.log("  - [major].csv files");
		console.log("  - [major].json files");
	} catch (error) {
		console.error("‚ùå Error during scraping:", error);
		throw error; // Re-throw to be caught by the outer handler
	}
}

// Run the full process with proper exit handling
runFullScraping()
	.then(() => {
		console.log("‚ú® All scraping completed, exiting process...");
		process.exit(0);
	})
	.catch((error) => {
		console.error("‚ùå Fatal error in scraping process:", error);
		process.exit(1);
	});
